# API Keys for Deep Research Agent Example
# Copy this file to .env and fill in your actual API keys

# === OpenAI-compatible Model Configuration ===
# Required: API key for authentication
OPENAI_API_KEY=sk-...

# Optional: Model name (default: gpt-4o)
# Examples: gpt-4o, gpt-4-turbo, gpt-3.5-turbo
OPENAI_MODEL=gpt-4o

# Optional: Base URL for non-OpenAI endpoints
# Examples:
#   - https://api.openai.com/v1 (default)
#   - https://api.azure.com/openai/deployments/model-name/ (Azure)
#   - http://localhost:8000/v1 (local ollama/vllm/etc.)
# OPENAI_BASE_URL=https://api.openai.com/v1

# Optional: Temperature for sampling (default: 0.0)
# Range: 0.0-2.0 (higher = more creative)
OPENAI_TEMPERATURE=0.0

# Optional: Top-p for nucleus sampling (default: 1.0)
# Range: 0.0-1.0
OPENAI_TOP_P=1.0

# Optional: Maximum tokens in response
# If not set, uses model's default
# OPENAI_MAX_TOKENS=2048

# === Other API Keys ===
# Tavily API Key (for web search)
TAVILY_API_KEY=tvly-...

# LangSmith API Key (required for LangGraph local server)
# Get your key at: https://smith.langchain.com/settings
# LANGSMITH_API_KEY=lsv2_pt_your_api_key_here
